{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from Controller import *\n",
    "from Model_builds import *\n",
    "import tensorflow as tf\n",
    "os.chdir('..')\n",
    "dir=os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 1: simple vision transformer network with 1 layer and 8x8 patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Vision_transformer_single(embed_dim=254, input_shape=(96,96,3), \n",
    "                       num_heads=4, dropout_rate=0.1, num_classes=1, feed_forward_factor=2, patch_size=(8,8))\n",
    "\n",
    "dir=os.getcwd()\n",
    "train_gen, val_gen = get_pcam_generators(dir+'\\Data')\n",
    "\n",
    "model_name='ViT_with_patch2'\n",
    "model , callbacks_list = model_preparation(model,model_name,dir)\n",
    "\n",
    "epochs=5\n",
    "model, history = train_model(model, train_gen, val_gen, epochs, callbacks_list)\n",
    "\n",
    "accuracy, recall, roc_auc, confusion_matrix = evaluate_model(model, val_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "double cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.8007\n",
      "Epoch 1: val_loss improved from inf to 0.51994, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\CNN_double3_weights.keras\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.4343 - accuracy: 0.8007 - val_loss: 0.5199 - val_accuracy: 0.7416\n",
      "500/500 [==============================] - 10s 20ms/step\n",
      "Accuracy: 0.5000\n",
      "Recall: 1.0000\n",
      "area under curve: 0.4945\n",
      "[[   0    0]\n",
      " [8000 8000]]\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 1.8820 - accuracy: 0.5000\n",
      "1.8820265531539917\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "model1 = CNN_double()\n",
    "\n",
    "dir=os.getcwd()\n",
    "train_gen, val_gen = get_pcam_generators(dir+'\\Data')\n",
    "\n",
    "model_name='CNN_double3'\n",
    "model1 , callbacks_list = model_preparation(model1,model_name,dir)\n",
    "\n",
    "epochs=1\n",
    "model1, history = train_model(model1, train_gen, val_gen, epochs, callbacks_list)\n",
    "\n",
    "accuracy, recall, roc_auc, confusion_matrix = evaluate_model(model, val_gen)\n",
    "\n",
    "steps = val_gen.samples // val_gen.batch_size\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracye = model.evaluate(val_gen, steps=steps)\n",
    "print(loss)\n",
    "print(accuracye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.882026195526123\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(accuracye)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hybrid 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.4870 - accuracy: 0.7740\n",
      "Epoch 1: val_loss improved from inf to 0.94341, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\single_hybrid3_weights.keras\n",
      "4500/4500 [==============================] - 106s 23ms/step - loss: 0.4869 - accuracy: 0.7741 - val_loss: 0.9434 - val_accuracy: 0.5932\n",
      "Epoch 2/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.8038\n",
      "Epoch 2: val_loss did not improve from 0.94341\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.4411 - accuracy: 0.8038 - val_loss: 0.9941 - val_accuracy: 0.5651\n",
      "Epoch 3/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.7930\n",
      "Epoch 3: val_loss improved from 0.94341 to 0.86694, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\single_hybrid3_weights.keras\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.4550 - accuracy: 0.7930 - val_loss: 0.8669 - val_accuracy: 0.5633\n",
      "Epoch 4/20\n",
      "4498/4500 [============================>.] - ETA: 0s - loss: 0.4426 - accuracy: 0.8011\n",
      "Epoch 4: val_loss did not improve from 0.86694\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.4425 - accuracy: 0.8011 - val_loss: 0.8758 - val_accuracy: 0.5699\n",
      "Epoch 5/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.8076\n",
      "Epoch 5: val_loss improved from 0.86694 to 0.43544, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\single_hybrid3_weights.keras\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.4294 - accuracy: 0.8076 - val_loss: 0.4354 - val_accuracy: 0.8062\n",
      "Epoch 6/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8103\n",
      "Epoch 6: val_loss improved from 0.43544 to 0.40724, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\single_hybrid3_weights.keras\n",
      "4500/4500 [==============================] - 101s 23ms/step - loss: 0.4247 - accuracy: 0.8103 - val_loss: 0.4072 - val_accuracy: 0.8169\n",
      "Epoch 7/20\n",
      "4498/4500 [============================>.] - ETA: 0s - loss: 0.4221 - accuracy: 0.8116\n",
      "Epoch 7: val_loss did not improve from 0.40724\n",
      "4500/4500 [==============================] - 101s 23ms/step - loss: 0.4221 - accuracy: 0.8116 - val_loss: 0.4481 - val_accuracy: 0.8002\n",
      "Epoch 8/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.4150 - accuracy: 0.8148\n",
      "Epoch 8: val_loss did not improve from 0.40724\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.4150 - accuracy: 0.8148 - val_loss: 0.4426 - val_accuracy: 0.7951\n",
      "Epoch 9/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8150\n",
      "Epoch 9: val_loss did not improve from 0.40724\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.4140 - accuracy: 0.8150 - val_loss: 0.4101 - val_accuracy: 0.8123\n",
      "Epoch 10/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.8188\n",
      "Epoch 10: val_loss did not improve from 0.40724\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.4059 - accuracy: 0.8188 - val_loss: 0.8184 - val_accuracy: 0.6364\n",
      "Epoch 11/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.3946 - accuracy: 0.8242\n",
      "Epoch 11: val_loss improved from 0.40724 to 0.38855, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\single_hybrid3_weights.keras\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.3946 - accuracy: 0.8242 - val_loss: 0.3886 - val_accuracy: 0.8266\n",
      "Epoch 12/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.3999 - accuracy: 0.8224\n",
      "Epoch 12: val_loss did not improve from 0.38855\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.3999 - accuracy: 0.8224 - val_loss: 0.3998 - val_accuracy: 0.8274\n",
      "Epoch 13/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8279\n",
      "Epoch 13: val_loss did not improve from 0.38855\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.3905 - accuracy: 0.8279 - val_loss: 0.3936 - val_accuracy: 0.8269\n",
      "Epoch 14/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.8275\n",
      "Epoch 14: val_loss did not improve from 0.38855\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.3899 - accuracy: 0.8275 - val_loss: 0.3925 - val_accuracy: 0.8228\n",
      "Epoch 15/20\n",
      "4498/4500 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8311\n",
      "Epoch 15: val_loss improved from 0.38855 to 0.37520, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\single_hybrid3_weights.keras\n",
      "4500/4500 [==============================] - 97s 22ms/step - loss: 0.3820 - accuracy: 0.8311 - val_loss: 0.3752 - val_accuracy: 0.8374\n",
      "Epoch 16/20\n",
      "4498/4500 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8318\n",
      "Epoch 16: val_loss did not improve from 0.37520\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.3815 - accuracy: 0.8319 - val_loss: 0.4141 - val_accuracy: 0.8136\n",
      "Epoch 17/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8326\n",
      "Epoch 17: val_loss improved from 0.37520 to 0.37054, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\single_hybrid3_weights.keras\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.3797 - accuracy: 0.8326 - val_loss: 0.3705 - val_accuracy: 0.8401\n",
      "Epoch 18/20\n",
      "4498/4500 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8323\n",
      "Epoch 18: val_loss did not improve from 0.37054\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.3789 - accuracy: 0.8324 - val_loss: 0.3887 - val_accuracy: 0.8253\n",
      "Epoch 19/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.8363\n",
      "Epoch 19: val_loss improved from 0.37054 to 0.35967, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\single_hybrid3_weights.keras\n",
      "4500/4500 [==============================] - 97s 22ms/step - loss: 0.3733 - accuracy: 0.8363 - val_loss: 0.3597 - val_accuracy: 0.8439\n",
      "Epoch 20/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.3673 - accuracy: 0.8385\n",
      "Epoch 20: val_loss did not improve from 0.35967\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.3673 - accuracy: 0.8385 - val_loss: 0.5198 - val_accuracy: 0.7573\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.5198 - accuracy: 0.7573\n",
      "loss: 0.5198\n",
      "accuracy: 0.7573\n",
      "500/500 [==============================] - 10s 20ms/step\n",
      "[[5521 2479]\n",
      " [5541 2459]]\n",
      "recall: 0.3074\n",
      "area under curve: 0.5029\n"
     ]
    }
   ],
   "source": [
    "model = Hybrid_single(patch_size=(16,16))\n",
    "\n",
    "dir=os.getcwd()\n",
    "train_gen, val_gen = get_pcam_generators(dir+'\\Data')\n",
    "\n",
    "model_name='single_hybrid3'\n",
    "model , callbacks_list = model_preparation(model,model_name,dir)\n",
    "\n",
    "epochs=20\n",
    "model, history = train_model(model, train_gen, val_gen, epochs, callbacks_list)\n",
    "\n",
    "accuracy, recall, roc_auc, confusion_matrix = evaluate_model(model, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.7899\n",
      "Epoch 1: val_loss improved from inf to 0.55116, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\double_hybrid2_weights.keras\n",
      "4500/4500 [==============================] - 637s 140ms/step - loss: 0.4630 - accuracy: 0.7899 - val_loss: 0.5512 - val_accuracy: 0.7331\n",
      "Epoch 2/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.8280\n",
      "Epoch 2: val_loss did not improve from 0.55116\n",
      "4500/4500 [==============================] - 594s 132ms/step - loss: 0.3908 - accuracy: 0.8280 - val_loss: 0.5682 - val_accuracy: 0.7456\n",
      "Epoch 3/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8400\n",
      "Epoch 3: val_loss improved from 0.55116 to 0.38717, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\double_hybrid2_weights.keras\n",
      "4500/4500 [==============================] - 571s 127ms/step - loss: 0.3658 - accuracy: 0.8400 - val_loss: 0.3872 - val_accuracy: 0.8405\n",
      "Epoch 4/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8471\n",
      "Epoch 4: val_loss improved from 0.38717 to 0.35133, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\double_hybrid2_weights.keras\n",
      "4500/4500 [==============================] - 593s 132ms/step - loss: 0.3494 - accuracy: 0.8471 - val_loss: 0.3513 - val_accuracy: 0.8457\n",
      "Epoch 5/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.8503\n",
      "Epoch 5: val_loss did not improve from 0.35133\n",
      "4500/4500 [==============================] - 627s 139ms/step - loss: 0.3400 - accuracy: 0.8503 - val_loss: 0.3567 - val_accuracy: 0.8497\n",
      "Epoch 6/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8560\n",
      "Epoch 6: val_loss did not improve from 0.35133\n",
      "4500/4500 [==============================] - 574s 127ms/step - loss: 0.3301 - accuracy: 0.8560 - val_loss: 0.3863 - val_accuracy: 0.8388\n",
      "Epoch 7/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8594\n",
      "Epoch 7: val_loss did not improve from 0.35133\n",
      "4500/4500 [==============================] - 225s 50ms/step - loss: 0.3218 - accuracy: 0.8594 - val_loss: 0.3713 - val_accuracy: 0.8450\n",
      "Epoch 8/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.3117 - accuracy: 0.8643\n",
      "Epoch 8: val_loss improved from 0.35133 to 0.33443, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\double_hybrid2_weights.keras\n",
      "4500/4500 [==============================] - 140s 31ms/step - loss: 0.3117 - accuracy: 0.8643 - val_loss: 0.3344 - val_accuracy: 0.8640\n",
      "Epoch 9/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.8704\n",
      "Epoch 9: val_loss improved from 0.33443 to 0.33063, saving model to d:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging/metadata\\double_hybrid2_weights.keras\n",
      "4500/4500 [==============================] - 141s 31ms/step - loss: 0.2993 - accuracy: 0.8705 - val_loss: 0.3306 - val_accuracy: 0.8630\n",
      "Epoch 10/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.2846 - accuracy: 0.8792\n",
      "Epoch 10: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 141s 31ms/step - loss: 0.2846 - accuracy: 0.8792 - val_loss: 0.3463 - val_accuracy: 0.8577\n",
      "Epoch 11/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.8946\n",
      "Epoch 11: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 138s 31ms/step - loss: 0.2568 - accuracy: 0.8946 - val_loss: 0.4579 - val_accuracy: 0.8146\n",
      "Epoch 12/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9115\n",
      "Epoch 12: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 139s 31ms/step - loss: 0.2242 - accuracy: 0.9115 - val_loss: 0.3876 - val_accuracy: 0.8551\n",
      "Epoch 13/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.1858 - accuracy: 0.9298\n",
      "Epoch 13: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 139s 31ms/step - loss: 0.1857 - accuracy: 0.9298 - val_loss: 0.5097 - val_accuracy: 0.8249\n",
      "Epoch 14/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9449\n",
      "Epoch 14: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 139s 31ms/step - loss: 0.1499 - accuracy: 0.9449 - val_loss: 0.4908 - val_accuracy: 0.8284\n",
      "Epoch 15/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9572\n",
      "Epoch 15: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 138s 31ms/step - loss: 0.1224 - accuracy: 0.9572 - val_loss: 0.5155 - val_accuracy: 0.8351\n",
      "Epoch 16/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9648\n",
      "Epoch 16: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 143s 32ms/step - loss: 0.1010 - accuracy: 0.9648 - val_loss: 0.6505 - val_accuracy: 0.8213\n",
      "Epoch 17/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9713\n",
      "Epoch 17: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 139s 31ms/step - loss: 0.0836 - accuracy: 0.9712 - val_loss: 0.6872 - val_accuracy: 0.8278\n",
      "Epoch 18/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.0718 - accuracy: 0.9758\n",
      "Epoch 18: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 140s 31ms/step - loss: 0.0718 - accuracy: 0.9758 - val_loss: 0.5431 - val_accuracy: 0.8445\n",
      "Epoch 19/20\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9793\n",
      "Epoch 19: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 138s 31ms/step - loss: 0.0627 - accuracy: 0.9793 - val_loss: 0.6322 - val_accuracy: 0.8371\n",
      "Epoch 20/20\n",
      "4499/4500 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9815\n",
      "Epoch 20: val_loss did not improve from 0.33063\n",
      "4500/4500 [==============================] - 140s 31ms/step - loss: 0.0566 - accuracy: 0.9815 - val_loss: 0.7036 - val_accuracy: 0.8333\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.7036 - accuracy: 0.8333\n",
      "loss: 0.7036\n",
      "accuracy: 0.8333\n",
      "500/500 [==============================] - 10s 19ms/step\n",
      "[[4003 3997]\n",
      " [3950 4050]]\n",
      "recall: 0.5062\n",
      "area under curve: 0.5020\n"
     ]
    }
   ],
   "source": [
    "model = Hybrid_double(patch_size=(16,16))\n",
    "\n",
    "dir=os.getcwd()\n",
    "train_gen, val_gen = get_pcam_generators(dir+'\\Data')\n",
    "\n",
    "model_name='double_hybrid2'\n",
    "model , callbacks_list = model_preparation(model,model_name,dir)\n",
    "\n",
    "epochs=20\n",
    "model, history = train_model(model, train_gen, val_gen, epochs, callbacks_list)\n",
    "\n",
    "accuracy, recall, roc_auc, confusion_matrix = evaluate_model(model, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n",
      " 206/4500 [>.............................] - ETA: 5:11 - loss: 0.6005 - accuracy: 0.7224"
     ]
    }
   ],
   "source": [
    "model = Hybrid_double(patch_size=(16,16))\n",
    "\n",
    "dir=os.getcwd()\n",
    "train_gen, val_gen = get_pcam_generators(dir+'\\Data')\n",
    "\n",
    "model_name='double_hybrid2'\n",
    "model , callbacks_list = model_preparation(model,model_name,dir)\n",
    "\n",
    "epochs=1\n",
    "model, history = train_model(model, train_gen, val_gen, epochs, callbacks_list)\n",
    "\n",
    "loss, accuracy, AUC, recall = evaluate_model(model, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 10s 20ms/step - loss: 1.8820 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "steps = val_gen.samples // val_gen.batch_size\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_gen, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hybrid double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "  54/4500 [..............................] - ETA: 2:58 - loss: 0.8113 - accuracy: 0.5909"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m model , callbacks_list \u001b[38;5;241m=\u001b[39m model_preparation(model,model_name,\u001b[38;5;28mdir\u001b[39m)\n\u001b[0;32m      9\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m---> 10\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m accuracy, recall, roc_auc, confusion_matrix \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_gen)\n",
      "File \u001b[1;32md:\\TUE\\Active\\AI_in_MIA\\8p361-project-imaging\\hybrid\\Controller.py:70\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_gen, val_gen, epochs, callbacks_list)\u001b[0m\n\u001b[0;32m     67\u001b[0m val_steps \u001b[38;5;241m=\u001b[39m val_gen\u001b[38;5;241m.\u001b[39mn\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mval_gen\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m     69\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_FORCE_GPU_ALLOW_GROWTH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 70\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Hybrid_double(patch_size=(8,8))\n",
    "\n",
    "dir=os.getcwd()\n",
    "train_gen, val_gen = get_pcam_generators(dir+'\\Data')\n",
    "\n",
    "model_name='single_hybrid1'\n",
    "model , callbacks_list = model_preparation(model,model_name,dir)\n",
    "\n",
    "epochs=5\n",
    "model, history = train_model(model, train_gen, val_gen, epochs, callbacks_list)\n",
    "\n",
    "accuracy, recall, roc_auc, confusion_matrix = evaluate_model(model, val_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

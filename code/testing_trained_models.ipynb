{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, GlobalAveragePooling1D, DepthwiseConv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir,'train+val','train')\n",
    "     valid_path = os.path.join(base_dir,'train+val','valid')\n",
    "\n",
    "\n",
    "     RESCALING_FACTOR = 1./255\n",
    "\n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     return train_gen, val_gen\n",
    "\n",
    "os.chdir('..')\n",
    "dir=os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# et the filepath where the trained model is saved (should be in the 'metadata' directory with a .keras extension)\n",
    "model_name='double_CNN_1'\n",
    "model_filepath = dir+'/metadata/'+model_name + '_weights.keras'\n",
    "\n",
    "# load the model from the given filepath\n",
    "model=tf.keras.models.load_model(model_filepath)\n",
    "\n",
    "train_gen, val_gen = get_pcam_generators(dir+'\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 148s 280ms/step - loss: 0.3737 - accuracy: 0.8399 - auc_2: 0.9214 - recall_2: 0.8121\n",
      "loss: 0.3737\n",
      "accuracy: 0.8399\n",
      "AUC: 0.9214\n",
      "Recall: 0.8121\n"
     ]
    }
   ],
   "source": [
    "steps = val_gen.samples // val_gen.batch_size  \n",
    "loss, accuracy, area_under_curve, recall = model.evaluate(val_gen, steps=steps)\n",
    "\n",
    "print(f'loss: {loss:.4f}')\n",
    "print(f'accuracy: {accuracy:.4f}')\n",
    "print(f'AUC: {area_under_curve:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 451/4500 [==>...........................] - ETA: 13:29"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten())  \u001b[38;5;66;03m# Returns a probability per image\u001b[39;00m\n\u001b[0;32m      2\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m y_pred_prob]\n\u001b[0;32m      3\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(val_gen\u001b[38;5;241m.\u001b[39mclasses)  \u001b[38;5;66;03m# The real labels (0 or 1) from the validation set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:2251\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 2251\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m   2253\u001b[0m             tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function(iterator)\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred_prob = list(model.predict(val_gen).flatten())  # Returns a probability per image\n",
    "y_pred=[1 if num >= .5 else 0 for num in y_pred_prob]\n",
    "y_true = list(val_gen.classes)  # The real labels (0 or 1) from the validation set\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average='binary') \n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "num_batches = 500\n",
    "predictions = []\n",
    "true = []\n",
    "\n",
    "# Iterate through the first 20 batches of the data generator\n",
    "for i, (batch_data, batch_labels) in enumerate(val_gen):\n",
    "    if i >= num_batches:\n",
    "        break  # Stop after 20 batches\n",
    "    \n",
    "    # Perform prediction on the batch\n",
    "    batch_predictions = model.predict(batch_data)  # You can also use model(batch_data, training=False)\n",
    "    \n",
    "    # Store predictions for later analysis (optional)\n",
    "    predictions.append(batch_predictions)\n",
    "    true.append(batch_labels)\n",
    "\n",
    "# After the loop, you can convert the predictions list into a single array (optional)\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true = np.concatenate(true, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'slice' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate through the generator\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data, batch_labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mval_gen\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(batch_data)\n\u001b[0;32m      7\u001b[0m     correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(batch_labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\keras\\preprocessing\\image.py:102\u001b[0m, in \u001b[0;36mIterator.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to retrieve element \u001b[39m\u001b[38;5;132;01m{idx}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut the Sequence \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas length \u001b[39m\u001b[38;5;132;01m{length}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx\u001b[38;5;241m=\u001b[39midx, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m    107\u001b[0m         )\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'slice' and 'int'"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Iterate through the generator\n",
    "for batch_data, batch_labels in val_gen:\n",
    "    predictions = model.predict(batch_data)\n",
    "    correct_predictions += np.sum(np.argmax(predictions, axis=-1) == np.argmax(batch_labels, axis=-1))\n",
    "    total_samples += batch_data.shape[0]\n",
    "\n",
    "accuracy = correct_predictions / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m batch_data, batch_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(val_gen)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#predictions=model.predict(val_gen.data)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "batch_data, batch_labels = enumerate(val_gen)\n",
    "#predictions=model.predict(val_gen.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(true, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9214428576464306"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area under curve: 0.4987\n",
      "[[4219 4225]\n",
      " [3781 3775]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    \n",
    "# Compute the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'area under curve: {roc_auc:.4f}')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "confusion_matrix=cm(y_pred,y_true)\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7921773,\n",
       " 0.3115063,\n",
       " 0.9832361,\n",
       " 0.5951114,\n",
       " 0.73207295,\n",
       " 0.51762617,\n",
       " 0.563621,\n",
       " 0.43391788,\n",
       " 0.0096657835,\n",
       " 0.8208519,\n",
       " 0.7215363,\n",
       " 0.97667664,\n",
       " 0.025579551,\n",
       " 0.22818902,\n",
       " 0.042315755,\n",
       " 0.037798014,\n",
       " 0.5644913,\n",
       " 0.8168321,\n",
       " 0.6083153,\n",
       " 0.82833314,\n",
       " 0.842327,\n",
       " 0.11371771,\n",
       " 0.11500127,\n",
       " 0.97037804,\n",
       " 0.19034566,\n",
       " 0.31499138,\n",
       " 0.1122832,\n",
       " 0.76609653,\n",
       " 0.6875551,\n",
       " 0.14121749,\n",
       " 0.3826993,\n",
       " 0.5190788,\n",
       " 0.42129472,\n",
       " 0.09194593,\n",
       " 0.6321239,\n",
       " 0.8966649,\n",
       " 0.7873881,\n",
       " 0.014704426,\n",
       " 0.6344121,\n",
       " 0.45554912,\n",
       " 0.77950454,\n",
       " 0.60650265,\n",
       " 0.9878221,\n",
       " 0.34395394,\n",
       " 0.3477565,\n",
       " 0.3021876,\n",
       " 0.10596876,\n",
       " 0.16137855,\n",
       " 0.27302727,\n",
       " 0.69876534,\n",
       " 0.3111097,\n",
       " 0.48570177,\n",
       " 0.69822526,\n",
       " 0.08216229,\n",
       " 0.6902751,\n",
       " 0.20450665,\n",
       " 0.015153106,\n",
       " 0.050185185,\n",
       " 0.8384885,\n",
       " 0.8439078,\n",
       " 0.3299557,\n",
       " 0.13387163,\n",
       " 0.57882965,\n",
       " 0.52197134,\n",
       " 0.09521651,\n",
       " 0.28900045,\n",
       " 0.34653977,\n",
       " 0.7088574,\n",
       " 0.22532967,\n",
       " 0.98155624,\n",
       " 0.9986545,\n",
       " 0.056945495,\n",
       " 0.231327,\n",
       " 0.017554505,\n",
       " 0.5069082,\n",
       " 0.32403713,\n",
       " 0.8583547,\n",
       " 0.1911538,\n",
       " 0.5767172,\n",
       " 0.09346247,\n",
       " 0.0578807,\n",
       " 0.91667867,\n",
       " 0.9647006,\n",
       " 0.46058375,\n",
       " 0.7961419,\n",
       " 0.66977495,\n",
       " 0.9153188,\n",
       " 0.74168795,\n",
       " 0.03752264,\n",
       " 0.6676596,\n",
       " 0.26008606,\n",
       " 0.009500514,\n",
       " 0.120807916,\n",
       " 0.99146247,\n",
       " 0.9986662,\n",
       " 0.058874242,\n",
       " 0.4496585,\n",
       " 0.46410888,\n",
       " 0.04868543,\n",
       " 0.17046943,\n",
       " 0.33744192,\n",
       " 0.20547982,\n",
       " 0.54267395,\n",
       " 0.32777792,\n",
       " 0.70675904,\n",
       " 0.26238492,\n",
       " 0.24282847,\n",
       " 0.8007554,\n",
       " 0.98314667,\n",
       " 0.87823796,\n",
       " 0.002071702,\n",
       " 0.7741502,\n",
       " 0.5084926,\n",
       " 0.6227613,\n",
       " 0.26136658,\n",
       " 0.98637414,\n",
       " 0.80018145,\n",
       " 0.88305783,\n",
       " 0.049381595,\n",
       " 0.80769116,\n",
       " 0.8441222,\n",
       " 0.68275684,\n",
       " 0.55411,\n",
       " 0.7872751,\n",
       " 0.21290195,\n",
       " 0.98146945,\n",
       " 0.8105131,\n",
       " 0.9801494,\n",
       " 0.6797567,\n",
       " 0.76083016,\n",
       " 0.38874337,\n",
       " 0.32368267,\n",
       " 0.4690611,\n",
       " 0.124407135,\n",
       " 0.50828105,\n",
       " 0.9711043,\n",
       " 0.30119246,\n",
       " 0.01690004,\n",
       " 0.93781334,\n",
       " 0.63137794,\n",
       " 0.09765334,\n",
       " 0.97220874,\n",
       " 0.56901795,\n",
       " 0.9924319,\n",
       " 0.652462,\n",
       " 0.31401646,\n",
       " 0.9380309,\n",
       " 0.8108104,\n",
       " 0.36615548,\n",
       " 0.95538276,\n",
       " 0.91273475,\n",
       " 0.8534428,\n",
       " 0.01598523,\n",
       " 0.83019227,\n",
       " 0.89709187,\n",
       " 0.53564835,\n",
       " 0.41564158,\n",
       " 0.4656798,\n",
       " 0.70298535,\n",
       " 0.86135715,\n",
       " 0.22583376,\n",
       " 0.7111085,\n",
       " 0.07327834,\n",
       " 0.896444,\n",
       " 0.5040783,\n",
       " 0.19442622,\n",
       " 0.71198773,\n",
       " 0.6816308,\n",
       " 0.05465977,\n",
       " 0.22439297,\n",
       " 0.50710636,\n",
       " 0.1696735,\n",
       " 0.33337653,\n",
       " 0.3276812,\n",
       " 0.77450293,\n",
       " 0.77371025,\n",
       " 0.73121136,\n",
       " 0.74791485,\n",
       " 0.14041966,\n",
       " 0.13005209,\n",
       " 0.41708362,\n",
       " 0.80707115,\n",
       " 0.19378045,\n",
       " 0.7431266,\n",
       " 0.7749671,\n",
       " 0.5134775,\n",
       " 0.9279868,\n",
       " 0.9716437,\n",
       " 0.9025276,\n",
       " 0.5457099,\n",
       " 0.40248942,\n",
       " 0.26930892,\n",
       " 0.021939546,\n",
       " 0.6900452,\n",
       " 0.306151,\n",
       " 0.3487222,\n",
       " 0.13743708,\n",
       " 0.4394192,\n",
       " 0.60322076,\n",
       " 0.08901341,\n",
       " 0.25286254,\n",
       " 0.31249613,\n",
       " 0.66013646,\n",
       " 0.9535205,\n",
       " 0.6246509,\n",
       " 0.7506166,\n",
       " 0.11851928,\n",
       " 0.45815885,\n",
       " 0.033498447,\n",
       " 0.5480272,\n",
       " 0.74980694,\n",
       " 0.9851111,\n",
       " 0.7408035,\n",
       " 0.9357751,\n",
       " 0.26761264,\n",
       " 0.18137676,\n",
       " 0.9390328,\n",
       " 0.17971757,\n",
       " 0.9059963,\n",
       " 0.84071946,\n",
       " 0.1373801,\n",
       " 0.6976114,\n",
       " 0.2456229,\n",
       " 0.14004761,\n",
       " 0.033299387,\n",
       " 0.71251094,\n",
       " 0.909047,\n",
       " 0.997347,\n",
       " 0.72342354,\n",
       " 0.86192095,\n",
       " 0.36471885,\n",
       " 0.21389842,\n",
       " 0.9585589,\n",
       " 0.8090518,\n",
       " 0.9768665,\n",
       " 0.33635584,\n",
       " 0.07926035,\n",
       " 0.8589263,\n",
       " 0.066970974,\n",
       " 0.93736905,\n",
       " 0.5940631,\n",
       " 0.9655483,\n",
       " 0.1303986,\n",
       " 0.78335625,\n",
       " 0.7528881,\n",
       " 0.49772346,\n",
       " 0.19596289,\n",
       " 0.28665236,\n",
       " 0.81474644,\n",
       " 0.8341161,\n",
       " 0.80402905,\n",
       " 0.05436198,\n",
       " 0.15697895,\n",
       " 0.113660656,\n",
       " 0.83358765,\n",
       " 0.7930893,\n",
       " 0.4799627,\n",
       " 0.9263165,\n",
       " 0.6395147,\n",
       " 0.81824726,\n",
       " 0.09416115,\n",
       " 0.87563527,\n",
       " 0.9855355,\n",
       " 0.19785666,\n",
       " 0.45361486,\n",
       " 0.510268,\n",
       " 0.58515,\n",
       " 0.4757594,\n",
       " 0.45182958,\n",
       " 0.43876755,\n",
       " 0.016661057,\n",
       " 0.015490626,\n",
       " 0.9539246,\n",
       " 0.93423295,\n",
       " 0.47837713,\n",
       " 0.5858362,\n",
       " 0.03888078,\n",
       " 0.26008746,\n",
       " 0.08093917,\n",
       " 0.48347104,\n",
       " 0.04679634,\n",
       " 0.869611,\n",
       " 0.23526485,\n",
       " 0.6709051,\n",
       " 0.12569384,\n",
       " 0.4604541,\n",
       " 0.012792206,\n",
       " 0.39547,\n",
       " 0.4299234,\n",
       " 0.3364537,\n",
       " 0.50186753,\n",
       " 0.32075417,\n",
       " 0.42774835,\n",
       " 0.9458159,\n",
       " 0.1613,\n",
       " 0.49531522,\n",
       " 0.8167717,\n",
       " 0.9570372,\n",
       " 0.1801983,\n",
       " 0.96319306,\n",
       " 0.9220529,\n",
       " 0.35465243,\n",
       " 0.051652245,\n",
       " 0.10465912,\n",
       " 0.9946,\n",
       " 0.045403857,\n",
       " 0.98815846,\n",
       " 0.9978854,\n",
       " 0.7788195,\n",
       " 0.025929729,\n",
       " 0.6995584,\n",
       " 0.018278435,\n",
       " 0.026343567,\n",
       " 0.9967026,\n",
       " 0.740716,\n",
       " 0.067343004,\n",
       " 0.43336013,\n",
       " 0.7092425,\n",
       " 0.15886776,\n",
       " 0.97309613,\n",
       " 0.5046475,\n",
       " 0.8823506,\n",
       " 0.15486036,\n",
       " 0.16121572,\n",
       " 0.7403816,\n",
       " 0.031479932,\n",
       " 0.01369921,\n",
       " 0.48804793,\n",
       " 0.040355068,\n",
       " 0.5955086,\n",
       " 0.8715013,\n",
       " 0.02576621,\n",
       " 0.30939838,\n",
       " 0.7453379,\n",
       " 0.19093043,\n",
       " 0.7911699,\n",
       " 0.83186054,\n",
       " 0.1169406,\n",
       " 0.9777972,\n",
       " 0.06227415,\n",
       " 0.86601275,\n",
       " 0.75034046,\n",
       " 0.32383963,\n",
       " 0.19125822,\n",
       " 0.77665305,\n",
       " 0.143256,\n",
       " 0.15774606,\n",
       " 0.3185073,\n",
       " 0.28930596,\n",
       " 0.23980469,\n",
       " 0.24632719,\n",
       " 0.18238762,\n",
       " 0.83276445,\n",
       " 0.93577397,\n",
       " 0.9130076,\n",
       " 0.11004958,\n",
       " 0.72224396,\n",
       " 0.07511885,\n",
       " 0.09387096,\n",
       " 0.9678691,\n",
       " 0.026288258,\n",
       " 0.66566813,\n",
       " 0.2592407,\n",
       " 0.75160784,\n",
       " 0.2140094,\n",
       " 0.7604582,\n",
       " 0.016912065,\n",
       " 0.27423954,\n",
       " 0.18483184,\n",
       " 0.31545576,\n",
       " 0.42953902,\n",
       " 0.68068665,\n",
       " 0.51681644,\n",
       " 0.39226082,\n",
       " 0.75145835,\n",
       " 0.17435597,\n",
       " 0.028442131,\n",
       " 0.8769488,\n",
       " 0.029035125,\n",
       " 0.9032786,\n",
       " 0.7187914,\n",
       " 0.1762895,\n",
       " 0.62414026,\n",
       " 0.650278,\n",
       " 0.20202036,\n",
       " 0.6082877,\n",
       " 0.29075602,\n",
       " 0.21161105,\n",
       " 0.46754584,\n",
       " 0.9773643,\n",
       " 0.6549326,\n",
       " 0.107516825,\n",
       " 0.6264266,\n",
       " 0.42254055,\n",
       " 0.27022046,\n",
       " 0.85711044,\n",
       " 0.03149534,\n",
       " 0.026634028,\n",
       " 0.9667823,\n",
       " 0.7545663,\n",
       " 0.21088344,\n",
       " 0.0039834264,\n",
       " 0.728596,\n",
       " 0.16107643,\n",
       " 0.42364252,\n",
       " 0.809575,\n",
       " 0.5207653,\n",
       " 0.28725782,\n",
       " 0.50376123,\n",
       " 0.4790819,\n",
       " 0.074412294,\n",
       " 0.18995193,\n",
       " 0.4821849,\n",
       " 0.22799148,\n",
       " 0.056865904,\n",
       " 0.07965645,\n",
       " 0.2948089,\n",
       " 0.4648849,\n",
       " 0.54979295,\n",
       " 0.43856585,\n",
       " 0.019757012,\n",
       " 0.05326542,\n",
       " 0.19940929,\n",
       " 0.87554437,\n",
       " 0.28720877,\n",
       " 0.7976861,\n",
       " 0.41617537,\n",
       " 0.49742162,\n",
       " 0.19253199,\n",
       " 0.7533848,\n",
       " 0.9075436,\n",
       " 0.1456704,\n",
       " 0.5407617,\n",
       " 0.11687361,\n",
       " 0.0529755,\n",
       " 0.19122225,\n",
       " 0.4509477,\n",
       " 0.9911759,\n",
       " 0.3580202,\n",
       " 0.9249901,\n",
       " 0.56439453,\n",
       " 0.3201015,\n",
       " 0.94865865,\n",
       " 0.79398257,\n",
       " 0.38423645,\n",
       " 0.1721596,\n",
       " 0.009706428,\n",
       " 0.96122485,\n",
       " 0.21658874,\n",
       " 0.28101987,\n",
       " 0.8630034,\n",
       " 0.09784515,\n",
       " 0.22545606,\n",
       " 0.6151073,\n",
       " 0.08683036,\n",
       " 0.08532978,\n",
       " 0.63273954,\n",
       " 0.49127907,\n",
       " 0.5687017,\n",
       " 0.9060012,\n",
       " 0.10810158,\n",
       " 0.15335414,\n",
       " 0.02367133,\n",
       " 0.3994583,\n",
       " 0.6246326,\n",
       " 0.75590557,\n",
       " 0.45165628,\n",
       " 0.056971066,\n",
       " 0.528256,\n",
       " 0.98761326,\n",
       " 0.13938908,\n",
       " 0.119427204,\n",
       " 0.8023479,\n",
       " 0.036888123,\n",
       " 0.48664844,\n",
       " 0.9911817,\n",
       " 0.30233446,\n",
       " 0.75702,\n",
       " 0.15252069,\n",
       " 0.064541884,\n",
       " 0.31906638,\n",
       " 0.5045593,\n",
       " 0.6849195,\n",
       " 0.95357746,\n",
       " 0.91802555,\n",
       " 0.575311,\n",
       " 0.59349686,\n",
       " 0.047027603,\n",
       " 0.112202086,\n",
       " 0.85819316,\n",
       " 0.26287338,\n",
       " 0.2606442,\n",
       " 0.037984073,\n",
       " 0.3878051,\n",
       " 0.77061534,\n",
       " 0.6695077,\n",
       " 0.9247837,\n",
       " 0.097683646,\n",
       " 0.6350054,\n",
       " 0.13833594,\n",
       " 0.8140297,\n",
       " 0.93706733,\n",
       " 0.43401754,\n",
       " 0.22472906,\n",
       " 0.6928365,\n",
       " 0.1438427,\n",
       " 0.025142664,\n",
       " 0.8254516,\n",
       " 0.3265525,\n",
       " 0.71626276,\n",
       " 0.08687374,\n",
       " 0.1302091,\n",
       " 0.9687042,\n",
       " 0.5839814,\n",
       " 0.6342515,\n",
       " 0.7856897,\n",
       " 0.8153663,\n",
       " 0.022529079,\n",
       " 0.44296736,\n",
       " 0.6054111,\n",
       " 0.12499186,\n",
       " 0.19432053,\n",
       " 0.18083824,\n",
       " 0.59331405,\n",
       " 0.10813724,\n",
       " 0.413907,\n",
       " 0.93196845,\n",
       " 0.67290086,\n",
       " 0.6393838,\n",
       " 0.51472545,\n",
       " 0.18530053,\n",
       " 0.22556204,\n",
       " 0.60772204,\n",
       " 0.21139653,\n",
       " 0.041542113,\n",
       " 0.6040104,\n",
       " 0.093061835,\n",
       " 0.8019808,\n",
       " 0.54353553,\n",
       " 0.5737808,\n",
       " 0.13019465,\n",
       " 0.6648429,\n",
       " 0.27356902,\n",
       " 0.82549834,\n",
       " 0.9742114,\n",
       " 0.5376918,\n",
       " 0.71686053,\n",
       " 0.57432,\n",
       " 0.93860656,\n",
       " 0.16838723,\n",
       " 0.7816837,\n",
       " 0.20587797,\n",
       " 0.99364483,\n",
       " 0.91309994,\n",
       " 0.76707506,\n",
       " 0.99662715,\n",
       " 0.078809604,\n",
       " 0.35771745,\n",
       " 0.031398103,\n",
       " 0.69484615,\n",
       " 0.4726871,\n",
       " 0.46696675,\n",
       " 0.2830309,\n",
       " 0.12511224,\n",
       " 0.99122876,\n",
       " 0.8681119,\n",
       " 0.07828094,\n",
       " 0.09352999,\n",
       " 0.6961225,\n",
       " 0.042144306,\n",
       " 0.07687772,\n",
       " 0.61353374,\n",
       " 0.96320534,\n",
       " 0.42565814,\n",
       " 0.9951621,\n",
       " 0.8298962,\n",
       " 0.6618031,\n",
       " 0.15422916,\n",
       " 0.78177726,\n",
       " 0.6342919,\n",
       " 0.8636584,\n",
       " 0.34594026,\n",
       " 0.89412296,\n",
       " 0.012106122,\n",
       " 0.49534246,\n",
       " 0.09241918,\n",
       " 0.5826544,\n",
       " 0.4281988,\n",
       " 0.97254306,\n",
       " 0.97488624,\n",
       " 0.6935276,\n",
       " 0.7452456,\n",
       " 0.23249425,\n",
       " 0.16329122,\n",
       " 0.7509539,\n",
       " 0.88165617,\n",
       " 0.90512764,\n",
       " 0.789479,\n",
       " 0.2901736,\n",
       " 0.94375926,\n",
       " 0.7359555,\n",
       " 0.09611806,\n",
       " 0.027144037,\n",
       " 0.53068745,\n",
       " 0.37377697,\n",
       " 0.50678027,\n",
       " 0.5277896,\n",
       " 0.9599642,\n",
       " 0.94451904,\n",
       " 0.073199615,\n",
       " 0.8232052,\n",
       " 0.9694875,\n",
       " 0.7733271,\n",
       " 0.6993482,\n",
       " 0.5368117,\n",
       " 0.053106725,\n",
       " 0.7946824,\n",
       " 0.11727941,\n",
       " 0.12932356,\n",
       " 0.8482592,\n",
       " 0.746804,\n",
       " 0.69807667,\n",
       " 0.8120464,\n",
       " 0.07404955,\n",
       " 0.41648135,\n",
       " 0.7840917,\n",
       " 0.08262956,\n",
       " 0.9368941,\n",
       " 0.70916295,\n",
       " 0.75846106,\n",
       " 0.9933455,\n",
       " 0.9860915,\n",
       " 0.90716046,\n",
       " 0.7008657,\n",
       " 0.6897473,\n",
       " 0.06882593,\n",
       " 0.4735527,\n",
       " 0.029668067,\n",
       " 0.13248673,\n",
       " 0.863394,\n",
       " 0.62494874,\n",
       " 0.05814335,\n",
       " 0.71727735,\n",
       " 0.23761691,\n",
       " 0.049775522,\n",
       " 0.33475423,\n",
       " 0.20847124,\n",
       " 0.7635758,\n",
       " 0.12734745,\n",
       " 0.5275467,\n",
       " 0.11708787,\n",
       " 0.6640335,\n",
       " 0.76678145,\n",
       " 0.36092663,\n",
       " 0.0074080974,\n",
       " 0.70964456,\n",
       " 0.20464617,\n",
       " 0.9592116,\n",
       " 0.6770736,\n",
       " 0.26578104,\n",
       " 0.12455383,\n",
       " 0.7438175,\n",
       " 0.027663516,\n",
       " 0.17348008,\n",
       " 0.80803174,\n",
       " 0.9769561,\n",
       " 0.5523552,\n",
       " 0.4035932,\n",
       " 0.94627273,\n",
       " 0.568592,\n",
       " 0.66197896,\n",
       " 0.8889046,\n",
       " 0.7588664,\n",
       " 0.081843205,\n",
       " 0.058964066,\n",
       " 0.021913093,\n",
       " 0.038151935,\n",
       " 0.0757232,\n",
       " 0.6517103,\n",
       " 0.03936404,\n",
       " 0.86189044,\n",
       " 0.61567986,\n",
       " 0.8403421,\n",
       " 0.22716062,\n",
       " 0.9046843,\n",
       " 0.63156915,\n",
       " 0.1659829,\n",
       " 0.357703,\n",
       " 0.121196575,\n",
       " 0.19655749,\n",
       " 0.3770609,\n",
       " 0.8742454,\n",
       " 0.4038477,\n",
       " 0.2538583,\n",
       " 0.2944285,\n",
       " 0.098603606,\n",
       " 0.026233813,\n",
       " 0.5177581,\n",
       " 0.9825314,\n",
       " 0.38197115,\n",
       " 0.40542948,\n",
       " 0.94126785,\n",
       " 0.6370221,\n",
       " 0.04803408,\n",
       " 0.19177325,\n",
       " 0.8125558,\n",
       " 0.4897341,\n",
       " 0.98920035,\n",
       " 0.7360757,\n",
       " 0.6873858,\n",
       " 0.01228182,\n",
       " 0.6729796,\n",
       " 0.04275824,\n",
       " 0.73599476,\n",
       " 0.6524962,\n",
       " 0.9535067,\n",
       " 0.9672696,\n",
       " 0.59779364,\n",
       " 0.9973602,\n",
       " 0.62370795,\n",
       " 0.5167438,\n",
       " 0.7554365,\n",
       " 0.18313271,\n",
       " 0.9011438,\n",
       " 0.120150715,\n",
       " 0.5518943,\n",
       " 0.5463611,\n",
       " 0.34316614,\n",
       " 0.12250476,\n",
       " 0.19346073,\n",
       " 0.9063676,\n",
       " 0.0639513,\n",
       " 0.7830327,\n",
       " 0.042022996,\n",
       " 0.8859547,\n",
       " 0.8344987,\n",
       " 0.35064226,\n",
       " 0.05314546,\n",
       " 0.12640251,\n",
       " 0.9315387,\n",
       " 0.27876517,\n",
       " 0.9995401,\n",
       " 0.09951329,\n",
       " 0.4978695,\n",
       " 0.7330386,\n",
       " 0.046601087,\n",
       " 0.12595731,\n",
       " 0.115957655,\n",
       " 0.797449,\n",
       " 0.9951842,\n",
       " 0.13420567,\n",
       " 0.6233928,\n",
       " 0.23444217,\n",
       " 0.44605318,\n",
       " 0.64497894,\n",
       " 0.041951563,\n",
       " 0.18270387,\n",
       " 0.15170202,\n",
       " 0.94267845,\n",
       " 0.97483474,\n",
       " 0.9090181,\n",
       " 0.58599365,\n",
       " 0.8383572,\n",
       " 0.6729764,\n",
       " 0.53702235,\n",
       " 0.9275322,\n",
       " 0.7576648,\n",
       " 0.15360445,\n",
       " 0.23340484,\n",
       " 0.42926067,\n",
       " 0.02474503,\n",
       " 0.080269724,\n",
       " 0.74352,\n",
       " 0.1384607,\n",
       " 0.77736115,\n",
       " 0.06676274,\n",
       " 0.60990196,\n",
       " 0.64336073,\n",
       " 0.76382583,\n",
       " 0.79914594,\n",
       " 0.9563125,\n",
       " 0.9080478,\n",
       " 0.90759593,\n",
       " 0.9110042,\n",
       " 0.578076,\n",
       " 0.32021508,\n",
       " 0.6013014,\n",
       " 0.5044758,\n",
       " 0.875604,\n",
       " 0.7123954,\n",
       " 0.53731716,\n",
       " 0.3525727,\n",
       " 0.7489629,\n",
       " 0.7038562,\n",
       " 0.1193834,\n",
       " 0.035603736,\n",
       " 0.43059954,\n",
       " 0.13969833,\n",
       " 0.46346337,\n",
       " 0.92188686,\n",
       " 0.111641556,\n",
       " 0.12868439,\n",
       " 0.106723815,\n",
       " 0.9789412,\n",
       " 0.6045278,\n",
       " 0.7762746,\n",
       " 0.9219869,\n",
       " 0.9471411,\n",
       " 0.33853045,\n",
       " 0.056278057,\n",
       " 0.738892,\n",
       " 0.4907565,\n",
       " 0.46032387,\n",
       " 0.025684554,\n",
       " 0.5303611,\n",
       " 0.8115763,\n",
       " 0.022222457,\n",
       " 0.037761137,\n",
       " 0.26427677,\n",
       " 0.90872014,\n",
       " 0.9311823,\n",
       " 0.27031443,\n",
       " 0.040243883,\n",
       " 0.41864586,\n",
       " 0.10021545,\n",
       " 0.86387295,\n",
       " 0.41772768,\n",
       " 0.087667756,\n",
       " 0.4174674,\n",
       " 0.26891482,\n",
       " 0.21770741,\n",
       " 0.41815108,\n",
       " 0.32125098,\n",
       " 0.99772155,\n",
       " 0.9061646,\n",
       " 0.2561031,\n",
       " 0.93462646,\n",
       " 0.8787474,\n",
       " 0.5966393,\n",
       " 0.071244754,\n",
       " 0.6634488,\n",
       " 0.5961805,\n",
       " 0.8291907,\n",
       " 0.28518513,\n",
       " 0.16736229,\n",
       " 0.30390632,\n",
       " 0.1189574,\n",
       " 0.8706683,\n",
       " 0.15566592,\n",
       " 0.9384914,\n",
       " 0.056101494,\n",
       " 0.90245354,\n",
       " 0.99770993,\n",
       " 0.16157778,\n",
       " 0.27761522,\n",
       " 0.2601787,\n",
       " 0.46842372,\n",
       " 0.882322,\n",
       " 0.7918922,\n",
       " 0.9526825,\n",
       " 0.661958,\n",
       " 0.037438724,\n",
       " 0.90459037,\n",
       " 0.07702097,\n",
       " 0.2135207,\n",
       " 0.37499362,\n",
       " 0.03487673,\n",
       " 0.25808924,\n",
       " 0.2340203,\n",
       " 0.23477247,\n",
       " 0.7166886,\n",
       " 0.010579241,\n",
       " 0.67727065,\n",
       " 0.7875794,\n",
       " 0.7076724,\n",
       " 0.99943066,\n",
       " 0.08035001,\n",
       " 0.15120114,\n",
       " 0.05436501,\n",
       " 0.052523836,\n",
       " 0.9993706,\n",
       " 0.8637893,\n",
       " 0.11043942,\n",
       " 0.36202914,\n",
       " 0.23501396,\n",
       " 0.0028725557,\n",
       " 0.73762316,\n",
       " 0.74510455,\n",
       " 0.9958615,\n",
       " 0.6319401,\n",
       " 0.8068898,\n",
       " 0.07542144,\n",
       " 0.8211888,\n",
       " 0.8153598,\n",
       " 0.004321957,\n",
       " 0.9759347,\n",
       " 0.49783522,\n",
       " 0.42569834,\n",
       " 0.25559425,\n",
       " 0.6764559,\n",
       " 0.4995301,\n",
       " 0.70457864,\n",
       " 0.59202415,\n",
       " 0.5471887,\n",
       " 0.1480345,\n",
       " 0.6677366,\n",
       " 0.1649515,\n",
       " 0.9706779,\n",
       " 0.19297051,\n",
       " 0.9664985,\n",
       " 0.3714155,\n",
       " 0.84246457,\n",
       " 0.09747117,\n",
       " 0.04983224,\n",
       " 0.20653695,\n",
       " 0.14376009,\n",
       " 0.034727316,\n",
       " 0.4027086,\n",
       " 0.19492847,\n",
       " 0.8300572,\n",
       " 0.6374509,\n",
       " 0.9700229,\n",
       " 0.5315999,\n",
       " 0.84745526,\n",
       " 0.47984716,\n",
       " 0.36666197,\n",
       " 0.062205315,\n",
       " 0.6241199,\n",
       " 0.8544066,\n",
       " 0.9489782,\n",
       " 0.11161772,\n",
       " 0.2496145,\n",
       " 0.8109297,\n",
       " 0.9044451,\n",
       " 0.7020454,\n",
       " 0.34003755,\n",
       " 0.97874683,\n",
       " 0.99701184,\n",
       " 0.83298296,\n",
       " 0.64664924,\n",
       " 0.1730958,\n",
       " 0.76335186,\n",
       " 0.9804652,\n",
       " 0.7966069,\n",
       " 0.6573332,\n",
       " 0.8853949,\n",
       " 0.89279777,\n",
       " 0.09861576,\n",
       " 0.18897194,\n",
       " 0.17082831,\n",
       " 0.07951903,\n",
       " 0.31972855,\n",
       " 0.37789032,\n",
       " 0.09131924,\n",
       " 0.89217526,\n",
       " 0.42265028,\n",
       " 0.83229625,\n",
       " 0.0092744045,\n",
       " 0.80343914,\n",
       " 0.14115745,\n",
       " 0.58337903,\n",
       " 0.6765769,\n",
       " 0.28375563,\n",
       " 0.5401949,\n",
       " 0.025991669,\n",
       " 0.9714639,\n",
       " 0.6481627,\n",
       " 0.06390435,\n",
       " 0.6949988,\n",
       " 0.83365977,\n",
       " 0.0766928,\n",
       " 0.47707886,\n",
       " 0.07625219,\n",
       " 0.104880944,\n",
       " 0.40953127,\n",
       " 0.1934596,\n",
       " 0.6732315,\n",
       " 0.2687351,\n",
       " 0.4063542,\n",
       " 0.6229614,\n",
       " 0.48193264,\n",
       " 0.9442513,\n",
       " 0.6401851,\n",
       " 0.66899544,\n",
       " 0.9403354,\n",
       " 0.04784125,\n",
       " 0.071823925,\n",
       " 0.63351357,\n",
       " 0.66534925,\n",
       " 0.6916516,\n",
       " 0.99165684,\n",
       " 0.80355483,\n",
       " 0.17217392,\n",
       " 0.53067136,\n",
       " 0.15815988,\n",
       " 0.97095066,\n",
       " 0.59776837,\n",
       " 0.7851805,\n",
       " 0.90726703,\n",
       " 0.98684055,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20222787\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, GlobalAveragePooling1D, DepthwiseConv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir,'train+val','train')\n",
    "     valid_path = os.path.join(base_dir,'train+val','valid')\n",
    "\n",
    "\n",
    "     RESCALING_FACTOR = 1./255\n",
    "\n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     return train_gen, val_gen\n",
    "\n",
    "os.chdir('..')\n",
    "dir=os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# et the filepath where the trained model is saved (should be in the 'metadata' directory with a .keras extension)\n",
    "model_name='CoAtNet_2conv_4pool_2ViTdrp.3_drp.3_10e_btc32'\n",
    "model_filepath = dir+'/metadata/'+model_name + '_weights.keras'\n",
    "\n",
    "# load the model from the given filepath\n",
    "model=tf.keras.models.load_model(model_filepath)\n",
    "\n",
    "train_gen, val_gen = get_pcam_generators(dir+'\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 176s 336ms/step\n",
      "Accuracy: 0.4930\n",
      "Recall: 0.5683\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = list(model.predict(val_gen).flatten())  # Returns a probability per image\n",
    "y_pred=[1 if num >= .5 else 0 for num in y_pred_prob]\n",
    "y_true = list(val_gen.classes)  # The real labels (0 or 1) from the validation set\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average='binary') \n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498670640625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    \n",
    "# Compute the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3947, 3983],\n",
       "       [4053, 4017]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "cm(y_pred,y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
